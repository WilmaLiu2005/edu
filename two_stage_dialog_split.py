# å…ˆLLMï¼Œå†æ—¶é—´é—´éš”15åˆ†é’Ÿ
from openai import OpenAI
import random
import time
import os
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
import re
import json5
import pandas as pd
import csv
# ==============================    

MAX_WORKERS = 50
MAX_RETRIES = 3
INITIAL_RETRY_DELAY = 1
MAX_RETRY_DELAY = 3
API_KEY = "sk-0jErqj61bIYM135CEqhfj318rKIM1TIa"  # å¡«å†™ä½ çš„ API key
BASE_URL = "https://api-gateway.glm.ai/v1"
MODEL_NAME = "gpt-5-2025-08-07"  # æˆ–ä½ è‡ªå·±çš„æ¨¡å‹
INPUT_FOLDER = "/Users/vince/undergraduate/KEG/edu/Data/pre_validation5"   # è¾“å…¥ CSV æ–‡ä»¶å¤¹
OUTPUT_FOLDER = "/Users/vince/undergraduate/KEG/edu/test_split" # è¾“å‡º CSV æ–‡ä»¶å¤¹

os.makedirs(OUTPUT_FOLDER, exist_ok=True)

# ==============================
# GPT API è°ƒç”¨
# ==============================
def gpt_api_call(messages, model=MODEL_NAME):
    client = OpenAI(api_key=API_KEY, base_url=BASE_URL)
    for attempt in range(MAX_RETRIES):
        try:
            response = client.chat.completions.create(
                model=model,
                messages=messages,
                max_completion_tokens=10000
            )
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"Attempt {attempt + 1} failed: {str(e)}")
            if attempt < MAX_RETRIES - 1:
                delay = min(INITIAL_RETRY_DELAY * (2 ** attempt) + random.uniform(0, 1), MAX_RETRY_DELAY)
                time.sleep(delay)
            else:
                return None

# ==============================
# Prompt æ¨¡æ¿
# ==============================
PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä¸ªå¯¹è¯åˆ†æåŠ©æ‰‹ã€‚
ä»¥ä¸‹æ˜¯æŸä¸ªå­¦ç”Ÿå’Œ AI å­¦ä¼´çš„å®Œæ•´äº¤äº’è®°å½•ï¼ŒæŒ‰æ—¶é—´é¡ºåºæ’åˆ—ã€‚
æ¯æ¡è®°å½•åŒ…å«:
- è¡Œåºå·
- æé—®æ—¶é—´
- æé—®å†…å®¹
- AIå›å¤

è¯·å°†è¿™äº›äº¤äº’åˆ’åˆ†æˆå¤šæ®µç‹¬ç«‹çš„å¯¹è¯ï¼ˆsessionï¼‰ã€‚  
åˆ’åˆ†è§„åˆ™ï¼š
1. **å¿…é¡»ä¿æŒåŸå§‹é¡ºåºï¼Œä¸èƒ½æ‰“ä¹±æˆ–è·³è·ƒ**  
2. **å¦‚æœä¸¤æ¡äº¤äº’ä¹‹é—´çš„æ—¶é—´é—´éš”è¿‡é•¿ï¼Œå°±ä¸€å®šè¦åˆ†æˆæ–°çš„å¯¹è¯**  
3. **å¦‚æœè¯é¢˜å‘ç”Ÿæ˜æ˜¾å˜åŒ–ï¼Œä¹Ÿè¦å¼€å¯æ–°å¯¹è¯**  
4. å¦åˆ™è§†ä¸ºåŒä¸€æ®µå¯¹è¯  

è¾“å‡ºæ ¼å¼ï¼š
- JSON æ ¼å¼ï¼š{{è¡Œå·: å¯¹è¯ç¼–å·}}ï¼Œå¯¹è¯ç¼–å·ä» 1 å¼€å§‹  
- ä¸è¦è¾“å‡ºå…¶ä»–è¯´æ˜æˆ–æ–‡å­—  

äº¤äº’è®°å½•å¦‚ä¸‹ï¼š
{dialogues_json}
"""

# ==============================
# JSON è§£æï¼ˆé²æ£’ï¼‰
# ==============================
def robust_json_parse(text):
    # å»æ‰ ```json ... ``` åŒ…è£¹
    cleaned = re.sub(r"^```(?:json)?|```$", "", text.strip(), flags=re.MULTILINE).strip()
    try:
        return json.loads(cleaned)
    except Exception:
        try:
            return json5.loads(cleaned)
        except Exception:
            print("âš ï¸ JSON è§£æå¤±è´¥ï¼ŒåŸå§‹è¾“å‡ºï¼š", text[:200])
            return {}

# ==============================
# äºŒé˜¶æ®µåˆ’åˆ†é€»è¾‘
# ==============================
def two_stage_split(df, mapping, time_threshold=15):
    """
    Stage 1: æ ¹æ® LLM è¾“å‡ºçš„ mapping è¿›è¡Œåˆæ­¥åˆ†ç»„
    Stage 2: åœ¨æ¯ç»„å†…æŒ‰æ—¶é—´é—´éš” <= time_threshold (åˆ†é’Ÿ) å†æ¬¡åˆ’åˆ†
    """
    results = []
    df["æé—®æ—¶é—´"] = pd.to_datetime(df["æé—®æ—¶é—´"])

    for session_id in sorted(set(mapping.values()), key=lambda x: int(x)):
        indices = [int(k) - 1 for k, v in mapping.items() if str(v) == str(session_id)]
        group = df.iloc[indices].copy().sort_values("æé—®æ—¶é—´").reset_index(drop=True)

        # Stage 2: æ—¶é—´åˆ’åˆ†
        sub_session = 1
        current_chunk = [group.iloc[0]]

        for i in range(1, len(group)):
            delta = (group.iloc[i]["æé—®æ—¶é—´"] - group.iloc[i - 1]["æé—®æ—¶é—´"]).total_seconds() / 60
            if delta > time_threshold:
                results.append((session_id, sub_session, pd.DataFrame(current_chunk)))
                sub_session += 1
                current_chunk = [group.iloc[i]]
            else:
                current_chunk.append(group.iloc[i])

        if current_chunk:
            results.append((session_id, sub_session, pd.DataFrame(current_chunk)))

    return results

# ==============================
# å•ä¸ª CSV å¤„ç†å‡½æ•°
# ==============================
def process_csv(file_path, output_folder):
    df = pd.read_csv(file_path, encoding="utf-8-sig", engine="python", quotechar='"', doublequote=True)
    df.columns = df.columns.str.strip()
    df = df.sort_values(by="æé—®æ—¶é—´").reset_index(drop=True)

    # æå–å¿…è¦å­—æ®µ
    dialogues = []
    for idx, row in df.iterrows():
        dialogues.append({
            "è¡Œå·": int(idx) + 1,
            "æé—®æ—¶é—´": str(row["æé—®æ—¶é—´"]),
            "æé—®å†…å®¹": str(row["æé—®å†…å®¹"]),
            "AIå›å¤": str(row["AIå›å¤"])
        })

    dialogues_json = json.dumps(dialogues, ensure_ascii=False)
    prompt = PROMPT_TEMPLATE.format(dialogues_json=dialogues_json)

    messages = [
        {"role": "system", "content": "ä½ æ˜¯äº¤äº’è½®æ¬¡åˆ†å‰²åŠ©æ‰‹"},
        {"role": "user", "content": prompt}
    ]

    response = gpt_api_call(messages)
    if not response:
        print(f"âš ï¸ {os.path.basename(file_path)} åˆ†å‰²å¤±è´¥")
        return

    mapping = robust_json_parse(response)

    student_id = df["å­¦ç”ŸID"].iloc[0] if "å­¦ç”ŸID" in df.columns else os.path.splitext(os.path.basename(file_path))[0]

    # Two-stage åˆ†å‰²
    results = two_stage_split(df, mapping)

    seq = 1
    for session_id, sub_session, group in results:
        # ä½¿ç”¨ 4 ä½é›¶å¡«å……ï¼š0001, 0002, ...
        filename = f"{student_id}_{seq}.csv"
        output_csv = os.path.join(output_folder, filename)
        group.to_csv(output_csv, index=False, encoding="utf-8", quoting=csv.QUOTE_ALL)
        print(f"âœ… å·²ç”Ÿæˆ {output_csv}ï¼ˆåŸï¼š{session_id}_{sub_session} -> åºå· {seq}ï¼‰ï¼Œå…± {len(group)} è¡Œ")
        seq += 1

# ==============================
# ä¸»ç¨‹åºï¼ˆå¹¶å‘ï¼‰
# ==============================
def main():
    files = [f for f in os.listdir(INPUT_FOLDER) if f.endswith(".csv")]
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(process_csv, os.path.join(INPUT_FOLDER, f), OUTPUT_FOLDER): f for f in files}
        for future in as_completed(futures):
            file = futures[future]
            try:
                future.result()
            except Exception as e:
                print(f"âŒ å¤„ç† {file} å‡ºé”™: {str(e)}")

    print("ğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    main()